import matplotlib.pyplot as plt
from tqdm import tqdm
from typing import Dict, List, Any, Optional
import torch
import math 
import numpy as np
import sys
import json
import os
from datetime import datetime
import wandb
import matplotlib.pyplot as plt

def create_progress_bar(total: int, desc: str = "Training Progress"):
    """Return a tqdm progress bar for the given total steps."""
    return tqdm(
        total=total,
        desc=desc,
        unit="steps",
        bar_format="â•‘{bar:30}â•‘ {percentage:3.0f}% â”‚ {n_fmt}/{total_fmt} â”‚ â±ï¸ {elapsed} â”‚ â³ {remaining} â”‚ ğŸš€ {rate_fmt}",
        ncols=100,
        leave=False,
        colour="cyan",
        dynamic_ncols=True,
        position=0,
        disable=not sys.stdout.isatty()
    )

def init_history(keys: List[str]) -> Dict[str, List[float]]:
    """Initialize a history dict with empty lists for each metric key."""
    return {k: [] for k in keys}

def update_history(history: Dict[str, List[float]], metrics: Dict[str, Any]):
    """Append current metrics to history. Only keys present in history are recorded."""
    for key in history:
        if key in metrics:
            val = metrics[key]
            if torch.is_tensor(val):
                history[key].append(val.item())
            elif isinstance(val, (np.integer, np.floating)):
                history[key].append(float(val))
            else:
                history[key].append(float(val))

# ---------------------------------------------------------------------------
# Wandb Logging Functions
# ---------------------------------------------------------------------------
def ask_wandb_logging() -> bool:
    """
    í•™ìŠµ ì‹œì‘ ì „ì— wandb ë¡œê¹… ì—¬ë¶€ë¥¼ ì‚¬ìš©ìì—ê²Œ ë¬¼ì–´ë´…ë‹ˆë‹¤.
    Returns:
        True: wandb ë¡œê¹… ì‚¬ìš©
        False: wandb ë¡œê¹… ì‚¬ìš© ì•ˆí•¨
    """
    try:
        answer = input("Wandbì— ì‹¤í—˜ì„ ë¡œê¹…í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        if answer in ["y", "yes", "1"]:
            print("Wandb ë¡œê¹…ì„ í™œì„±í™”í•©ë‹ˆë‹¤.")
            return True
        else:
            print("Wandb ë¡œê¹…ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.")
            return False
    except Exception as e:
        print(f"ì…ë ¥ ì˜¤ë¥˜: {e}. ê¸°ë³¸ê°’(False)ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        return False

def init_wandb(env_name: str, model, cfg, device: str) -> bool:
    """
    Wandb ì´ˆê¸°í™” ë° ì„¤ì •
    
    Args:
        env_name: í™˜ê²½ ì´ë¦„
        model: ëª¨ë¸ ê°ì²´
        cfg: ì„¤ì • ê°ì²´
        device: ë””ë°”ì´ìŠ¤
        
    Returns:
        wandb_enabled: wandb ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ì‹¤í—˜ ì´ë¦„ ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        experiment_name = f"SCM_GAT_{env_name}_{timestamp}"
        
        # Wandb ì„¤ì •
        wandb_config = {
            "env_name": env_name,
            "num_agents": model.num_agents,
            "model": {
                "gat_type": model.gat_type,
                "hidden_dim": model.hidden_dim,
                "gat_dim": model.gat_dim,
                "action_dim": model.action_dim,
                "obs_dim": model.obs_dim
            },
            "training": {
                "lr": cfg.lr,
                "total_steps": cfg.total_steps,
                "gamma": cfg.gamma,
                "gae_lambda": cfg.gae_lambda,
                "ent_coef": cfg.ent_coef,
                "value_coef": cfg.value_coef,
                "max_grad_norm": getattr(cfg, 'clip_grad', 1.0)
            },
            "device": str(device)
        }
        
        # Wandb ì´ˆê¸°í™”
        wandb.init(
            project="SCM-GAT-MultiAgent",
            name=experiment_name,
            config=wandb_config,
            tags=[env_name, "SCM", "GAT", "MultiAgent"],
            notes=f"SCM-GAT Multi-Agent Training on {env_name}"
        )
        
        # ëª¨ë¸ êµ¬ì¡°ë¥¼ wandbì— ë¡œê·¸
        wandb.watch(model, log="all", log_freq=100)
        
        print(f"Wandb ì´ˆê¸°í™” ì™„ë£Œ: {experiment_name}")
        return True
        
    except Exception as e:
        print(f"Wandb ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def log_gradients(model, wandb_enabled: bool = True) -> Optional[Dict[str, float]]:
    """
    Gradient ì •ë³´ë¥¼ wandbì— ë¡œê·¸
    
    Args:
        model: ëª¨ë¸ ê°ì²´
        wandb_enabled: wandb í™œì„±í™” ì—¬ë¶€
        
    Returns:
        grad_norms: gradient norm ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    if not wandb_enabled:
        return None
        
    grad_norms = {}
    param_norms = {}
    
    for name, param in model.named_parameters():
        if param.grad is not None:
            # Gradient norm
            grad_norm = param.grad.norm().item()
            grad_norms[f"grad_norm/{name}"] = grad_norm
            
            # Parameter norm
            param_norm = param.norm().item()
            param_norms[f"param_norm/{name}"] = param_norm
            
            # Gradient/Parameter ratio
            if param_norm > 0:
                grad_param_ratio = grad_norm / param_norm
                grad_norms[f"grad_param_ratio/{name}"] = grad_param_ratio
    
    # ì „ì²´ gradient norm
    total_grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), float('inf'))
    grad_norms["grad_norm/total"] = total_grad_norm
    
    # Wandbì— ë¡œê·¸
    wandb.log(grad_norms)
    wandb.log(param_norms)
    
    return grad_norms

def log_causal_structure(causal_structure, wandb_enabled: bool = True, vmin=None, vmax=None):
    """
    Causal structureë¥¼ wandbì— ë¡œê·¸
    Args:
        causal_structure: ì¸ê³¼êµ¬ì¡° í…ì„œ
        wandb_enabled: wandb í™œì„±í™” ì—¬ë¶€
        vmin, vmax: heatmapì˜ ì»¬ëŸ¬ ë²”ìœ„ (Noneì´ë©´ ìë™ìœ¼ë¡œ ë¶„ìœ„ìˆ˜ ê¸°ë°˜)
    """
    if not wandb_enabled:
        return
    arr = causal_structure.detach().cpu().numpy()
    # ìë™ ë²”ìœ„ ì„¤ì •: 5%~95% ë¶„ìœ„ìˆ˜
    if vmin is None:
        vmin = np.percentile(arr, 5)
    if vmax is None:
        vmax = np.percentile(arr, 95)
    fig, ax = plt.subplots(figsize=(6, 5))
    im = ax.imshow(arr, cmap='viridis', vmin=vmin, vmax=vmax)
    ax.set_title('Causal Structure Matrix')
    ax.set_xlabel('Cause')
    ax.set_ylabel('Effect')
    plt.colorbar(im)
    wandb.log({"causal_structure": wandb.Image(fig)})
    plt.close(fig)
    # Causal structure í†µê³„
    causal_stats = {
        "causal_structure/mean": causal_structure.mean().item(),
        "causal_structure/std": causal_structure.std().item(),
        "causal_structure/max": causal_structure.max().item(),
        "causal_structure/min": causal_structure.min().item(),
        "causal_structure/sparsity": (causal_structure < 0.1).float().mean().item()
    }
    wandb.log(causal_stats)

def log_episode_returns(batch_returns: List[np.ndarray], wandb_enabled: bool = True):
    """
    Episode returnsë¥¼ wandbì— ë¡œê·¸
    
    Args:
        batch_returns: ë°°ì¹˜ë³„ ì—í”¼ì†Œë“œ ë¦¬í„´ ë¦¬ìŠ¤íŠ¸
        wandb_enabled: wandb í™œì„±í™” ì—¬ë¶€
    """
    if not wandb_enabled or len(batch_returns) == 0:
        return
        
    episode_return = batch_returns[-1]
    wandb.log({
        "episode_return/mean": np.mean(episode_return),
        "episode_return/std": np.std(episode_return),
        "episode_return/max": np.max(episode_return),
        "episode_return/min": np.min(episode_return)
    })

def log_metrics(metrics: Dict[str, float], wandb_enabled: bool = True):
    """
    ë©”íŠ¸ë¦­ì„ wandbì— ë¡œê·¸
    
    Args:
        metrics: ë¡œê·¸í•  ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
        wandb_enabled: wandb í™œì„±í™” ì—¬ë¶€
    """
    if wandb_enabled:
        wandb.log(metrics)

def finish_wandb(wandb_enabled: bool = True):
    """
    Wandb ì¢…ë£Œ
    
    Args:
        wandb_enabled: wandb í™œì„±í™” ì—¬ë¶€
    """
    if wandb_enabled:
        wandb.finish()
        print("Wandb ë¡œê¹… ì™„ë£Œ")

# ---------------------------------------------------------------------------
# Causal Structure Plotting Functions
# ---------------------------------------------------------------------------
def plot_causal_structure_evolution(causal_structure_list, output_dir, steps=None):
    import numpy as np
    import matplotlib.pyplot as plt
    arr = np.array(causal_structure_list)  # (steps, ...)
    n_phases = 4
    total_steps = arr.shape[0]
    phase_len = total_steps // n_phases
    fig, axes = plt.subplots(1, n_phases, figsize=(4*n_phases, 4))
    for i in range(n_phases):
        start = i * phase_len
        end = (i+1) * phase_len if i < n_phases-1 else total_steps
        phase_avg = arr[start:end].mean(axis=0)
        ax = axes[i]
        vmin = np.percentile(phase_avg, 5)
        vmax = np.percentile(phase_avg, 95)
        im = ax.imshow(phase_avg, cmap='viridis', vmin=vmin, vmax=vmax)
        ax.set_title(f'Phase {i+1}\nsteps {start}~{end}')
        ax.set_xlabel('Cause')
        ax.set_ylabel('Effect')
        fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
    plt.tight_layout()
    plt.savefig(f"{output_dir}/causal_structure_phases.png")
    plt.close()

def plot_sparsity_analysis(arr: np.ndarray, output_dir: str):
    """
    Causal structureì˜ sparsity ë³€í™” ë¶„ì„
    
    Args:
        arr: ì¸ê³¼êµ¬ì¡° ë°°ì—´ (steps, N, N)
        output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
    """
    steps, N, _ = arr.shape
    
    # Sparsity ê³„ì‚° (0ì— ê°€ê¹Œìš´ entryë“¤ì˜ ë¹„ìœ¨)
    sparsity_ratio = []
    mean_entries = []
    std_entries = []
    
    for step in range(steps):
        # ëŒ€ê°ì„  ì œì™¸ (self-influence ì œì™¸)
        off_diagonal = arr[step].copy()
        np.fill_diagonal(off_diagonal, 0)
        
        # Sparsity ratio (0.1 ì´í•˜ì˜ ê°’ë“¤ì˜ ë¹„ìœ¨)
        sparsity_ratio.append(np.mean(off_diagonal < 0.1))
        mean_entries.append(np.mean(off_diagonal))
        std_entries.append(np.std(off_diagonal))
    
    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 8))
    
    # Sparsity ratio ë³€í™”
    ax1.plot(sparsity_ratio, 'b-', linewidth=2)
    ax1.set_title('Sparsity Ratio Evolution (Ratio of entries < 0.1)')
    ax1.set_xlabel('Step')
    ax1.set_ylabel('Sparsity Ratio')
    ax1.grid(True, alpha=0.3)
    
    # Mean entry ë³€í™”
    ax2.plot(mean_entries, 'r-', linewidth=2)
    ax2.set_title('Mean Entry Value Evolution')
    ax2.set_xlabel('Step')
    ax2.set_ylabel('Mean Entry Value')
    ax2.grid(True, alpha=0.3)
    
    # Standard deviation ë³€í™”
    ax3.plot(std_entries, 'g-', linewidth=2)
    ax3.set_title('Entry Standard Deviation Evolution')
    ax3.set_xlabel('Step')
    ax3.set_ylabel('Standard Deviation')
    ax3.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f"{output_dir}/sparsity_analysis.png")
    plt.show()
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\n===== Sparsity Analysis =====")
    print(f"ì´ˆê¸° Sparsity Ratio: {sparsity_ratio[0]:.3f}")
    print(f"ìµœì¢… Sparsity Ratio: {sparsity_ratio[-1]:.3f}")
    print(f"Sparsity ë³€í™”: {sparsity_ratio[-1] - sparsity_ratio[0]:.3f}")
    print(f"ì´ˆê¸° í‰ê·  Entry: {mean_entries[0]:.3f}")
    print(f"ìµœì¢… í‰ê·  Entry: {mean_entries[-1]:.3f}")
    print(f"Entry ê°ì†Œìœ¨: {(mean_entries[0] - mean_entries[-1]) / mean_entries[0] * 100:.1f}%")

def plot_entry_statistics(arr: np.ndarray, output_dir: str):
    """
    Entry ë³€í™”ì˜ í†µê³„ì  ë¶„ì„
    
    Args:
        arr: ì¸ê³¼êµ¬ì¡° ë°°ì—´ (steps, N, N)
        output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
    """
    steps, N, _ = arr.shape
    
    # ê° entryì˜ ë³€í™”ëŸ‰ ê³„ì‚°
    initial_entries = arr[0]
    final_entries = arr[-1]
    change_entries = final_entries - initial_entries
    
    # ëŒ€ê°ì„  ì œê±°
    np.fill_diagonal(change_entries, 0)
    
    # ë³€í™”ëŸ‰ íˆìŠ¤í† ê·¸ë¨
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 3, 1)
    vmin = np.percentile(change_entries, 5)
    vmax = np.percentile(change_entries, 95)
    plt.hist(change_entries.flatten(), bins=20, alpha=0.7, color='blue')
    plt.title('Entry Change Distribution')
    plt.xlabel('Change in Entry Value')
    plt.ylabel('Frequency')
    
    # ê°ì†Œí•œ entryë“¤ì˜ ë¹„ìœ¨
    decreased_ratio = np.mean(change_entries < 0)
    increased_ratio = np.mean(change_entries > 0)
    unchanged_ratio = np.mean(change_entries == 0)
    
    plt.subplot(1, 3, 2)
    labels = ['Decreased', 'Increased', 'Unchanged']
    sizes = [decreased_ratio, increased_ratio, unchanged_ratio]
    colors = ['red', 'green', 'gray']
    plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%')
    plt.title('Entry Change Categories')
    
    # ê°€ì¥ í° ë³€í™”ë¥¼ ë³´ì¸ entryë“¤
    plt.subplot(1, 3, 3)
    flat_changes = change_entries.flatten()
    top_decreases = np.argsort(flat_changes)[:5]  # ê°€ì¥ í° ê°ì†Œ
    top_increases = np.argsort(flat_changes)[-5:]  # ê°€ì¥ í° ì¦ê°€
    
    plt.bar(range(5), flat_changes[top_decreases], color='red', alpha=0.7, label='Top Decreases')
    plt.bar(range(5, 10), flat_changes[top_increases], color='green', alpha=0.7, label='Top Increases')
    plt.title('Top 5 Entry Changes')
    plt.xlabel('Entry Index')
    plt.ylabel('Change Value')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig(f"{output_dir}/entry_statistics.png")
    plt.show()
    
    # í†µê³„ ì¶œë ¥
    print(f"\n===== Entry Change Statistics =====")
    print(f"ê°ì†Œí•œ Entry ë¹„ìœ¨: {decreased_ratio:.1%}")
    print(f"ì¦ê°€í•œ Entry ë¹„ìœ¨: {increased_ratio:.1%}")
    print(f"ë³€í™”ì—†ëŠ” Entry ë¹„ìœ¨: {unchanged_ratio:.1%}")
    print(f"í‰ê·  ë³€í™”ëŸ‰: {np.mean(change_entries):.3f}")
    print(f"ë³€í™”ëŸ‰ í‘œì¤€í¸ì°¨: {np.std(change_entries):.3f}")
    print(f"ìµœëŒ€ ê°ì†ŒëŸ‰: {np.min(change_entries):.3f}")
    print(f"ìµœëŒ€ ì¦ê°€ëŸ‰: {np.max(change_entries):.3f}")

# ---------------------------------------------------------------------------
# ê¸°ì¡´ í•¨ìˆ˜ë“¤
# ---------------------------------------------------------------------------

def save_experiment_config(config: Dict[str, Any], save_dir: str, experiment_name: str = ""):
    """
    ì‹¤í—˜ ì„¤ì •ê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        config: ì €ì¥í•  ì„¤ì • ë”•ì…”ë„ˆë¦¬
        save_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
        experiment_name: ì‹¤í—˜ ì´ë¦„ (ì„ íƒì‚¬í•­)
    """
    os.makedirs(save_dir, exist_ok=True)
    
    # í˜„ì¬ ì‹œê°„ì„ í¬í•¨í•œ íŒŒì¼ëª… ìƒì„±
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    if experiment_name:
        filename = f"config_{experiment_name}_{timestamp}.json"
    else:
        filename = f"config_{timestamp}.json"
    
    config_path = os.path.join(save_dir, filename)
    
    # torch tensorë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    def convert_tensors(obj):
        """Convert tensors and numpy types to JSON serializable format"""
        if isinstance(obj, torch.Tensor):
            return obj.cpu().numpy().tolist()
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {k: convert_tensors(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_tensors(item) for item in obj]
        else:
            return obj
    
    config_serializable = convert_tensors(config)
    
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config_serializable, f, indent=2, ensure_ascii=False)
    
    print(f"ì‹¤í—˜ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {config_path}")
    return config_path

def load_experiment_config(config_path: str) -> Dict[str, Any]:
    """
    ì €ì¥ëœ ì‹¤í—˜ ì„¤ì •ì„ JSON íŒŒì¼ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ë¡œë“œëœ ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    print(f"ì‹¤í—˜ ì„¤ì •ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {config_path}")
    return config

def create_config_summary(config: Dict[str, Any]) -> str:
    """
    ì„¤ì • ë”•ì…”ë„ˆë¦¬ì—ì„œ ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìš”ì•½í•œ ë¬¸ìì—´ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        
    Returns:
        í•˜ì´í¼íŒŒë¼ë¯¸í„° ìš”ì•½ ë¬¸ìì—´
    """
    summary_parts = []
    
    # ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ (í•„ìš”ì— ë”°ë¼ ìˆ˜ì • ê°€ëŠ¥)
    key_params = [
        'learning_rate', 'lr', 'batch_size', 'hidden_dim', 'gat_dim', 'z_dim',
        'num_agents', 'num_episodes', 'max_steps', 'gamma', 'tau',
        'use_gat', 'use_causal_gat', 'mixed_precision'
    ]
    
    for key in key_params:
        if key in config:
            value = config[key]
            if isinstance(value, (int, float, str, bool)):
                summary_parts.append(f"{key}: {value}")
            elif isinstance(value, list) and len(value) <= 5:
                summary_parts.append(f"{key}: {value}")
    
    return " | ".join(summary_parts)

def plot_history(history: Dict[str, List[float]], save_path: str = "training_history.png", 
                task_name: str = "", config: Optional[Dict[str, Any]] = None):
    """Plot each metric in history as subplots in a grid layout."""
    # ë¹„ì–´ìˆì§€ ì•Šì€ í‚¤ë§Œ ëª¨ìŒ
    keys = [k for k, v in history.items() if v]
    n = len(keys)
    if n == 0:
        return

    # ê²©ì í¬ê¸° ê³„ì‚°: cols = ceil(sqrt(n)), rows = ceil(n/cols)
    cols = math.ceil(math.sqrt(n))
    rows = math.ceil(n / cols)

    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 3 * rows))
    axes = axes.flatten()  # 1D arrayë¡œ ë³€í™˜

    for idx, key in enumerate(keys):
        ax = axes[idx]
        vals = history[key]
        steps = list(range(len(vals)))
        ax.plot(steps, vals)
        ax.set_title(f"{key}")
        ax.set_xlabel("epoch")
        ax.set_ylabel(key)
        ax.grid(True)

    # ë‚¨ëŠ” subplot ì¶•ì€ ìˆ¨ê¹ë‹ˆë‹¤.
    for j in range(idx + 1, len(axes)):
        axes[j].axis('off')

    # ì œëª©ì— task_nameê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ë³´ ì¶”ê°€
    title = "Training History"
    if task_name:
        title = f"Training History - {task_name}"
    
    if config:
        config_summary = create_config_summary(config)
        if config_summary:
            title += f"\n{config_summary}"
    
    fig.suptitle(title, fontsize=12, y=0.98)

    fig.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"Training history saved to: {save_path}")
    plt.show()  # ê·¸ë˜í”„ë¥¼ í™”ë©´ì— í‘œì‹œ

def plot_episode_returns(episode_returns, save_path: str = "episode_returns.png", 
                        task_name: str = "", config: Optional[Dict[str, Any]] = None):
    """
    episode_returns: List[np.ndarray]  (shape = (N_agents,))  ë˜ëŠ”
                     List[float]       (shape = ())
    """
    ep_arr = np.asarray(episode_returns)          # (B,)  ë˜ëŠ” (B, N) - BëŠ” ë°°ì¹˜ ìˆ˜
    batches = np.arange(1, ep_arr.shape[0] + 1)
    plt.figure(figsize=(8,4))

    if ep_arr.ndim == 1:          # ìŠ¤ì¹¼ë¼ ë¦¬í„´
        plt.plot(batches, ep_arr, label="total", alpha=0.1)
        # ì´ë™í‰ê· 
        window = 20  # ë°°ì¹˜ ê¸°ì¤€ìœ¼ë¡œ window í¬ê¸° ì¡°ì •
        if len(ep_arr) >= window:
            ma = np.convolve(ep_arr, np.ones(window)/window, mode="valid")
            plt.plot(batches[window-1:], ma, lw=2, label=f"{window}-batch mean")
    else:                         # ì—ì´ì „íŠ¸ë³„
        window = 20  # ë°°ì¹˜ ê¸°ì¤€ìœ¼ë¡œ window í¬ê¸° ì¡°ì •
        for i in range(ep_arr.shape[1]):
            # raw return (ì˜…ì€ ìƒ‰)
            plt.plot(batches, ep_arr[:, i], label=f"agent {i} (raw)", alpha=0.1)
            # ì´ë™í‰ê·  (ì§„í•œ ìƒ‰)
            if len(ep_arr[:, i]) >= window:
                ma = np.convolve(ep_arr[:, i], np.ones(window)/window, mode="valid")
                plt.plot(batches[window-1:], ma, lw=2, label=f"agent {i} {window}-batch mean")
        plt.legend()

    # ì œëª©ì— task_nameê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ë³´ ì¶”ê°€
    title = "Average Return per Batch"
    if task_name:
        title = f"Average Return per Batch - {task_name}"
    
    if config:
        config_summary = create_config_summary(config)
        if config_summary:
            title += f"\n{config_summary}"
    
    plt.title(title)
    plt.xlabel("Batch")
    plt.ylabel("Average Return")
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"Batch returns saved to: {save_path}")
    plt.show()  # ê·¸ë˜í”„ë¥¼ í™”ë©´ì— í‘œì‹œ

def plot_phase_success(episode_counts: List[int],
                       success_counts: List[int],
                       phase_names: Optional[List[str]] = None,
                       save_path: str = "phase_success.png",
                       task_name: str = "",
                       config: Optional[Dict[str, Any]] = None):
    """
    Plot bar chart of success rate per phase.
    """
    # Default phase names
    if phase_names is None:
        phase_names = [f"Phase {i+1}" for i in range(len(episode_counts))]
    # Compute success rates
    rates = []
    for eps, succ in zip(episode_counts, success_counts):
        if eps > 0:
            rates.append(succ / eps)
        else:
            rates.append(0.0)
    # Plot
    plt.figure()
    plt.bar(phase_names, rates)
    
    # ì œëª©ì— task_nameê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ë³´ ì¶”ê°€
    title = "Episode Success Rate by Phase"
    if task_name:
        title = f"Episode Success Rate by Phase - {task_name}"
    
    if config:
        config_summary = create_config_summary(config)
        if config_summary:
            title += f"\n{config_summary}"
    
    plt.title(title)
    plt.xlabel("Phase")
    plt.ylabel("Success Rate")
    plt.ylim(0, 1)
    plt.grid(axis='y')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"Phase success plot saved to: {save_path}")
    plt.show()  # ê·¸ë˜í”„ë¥¼ í™”ë©´ì— í‘œì‹œ

def save_all_results(history: Dict[str, List[float]], 
                    episode_returns: List, 
                    save_dir: str, 
                    task_name: str = "",
                    config: Optional[Dict[str, Any]] = None,
                    episode_counts: Optional[List[int]] = None,
                    success_counts: Optional[List[int]] = None,
                    phase_names: Optional[List[str]] = None):
    """
    ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ë¥¼ í•œ ë²ˆì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        history: í›ˆë ¨ íˆìŠ¤í† ë¦¬
        episode_returns: ì—í”¼ì†Œë“œ ë¦¬í„´ ë¦¬ìŠ¤íŠ¸
        save_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬
        task_name: íƒœìŠ¤í¬ ì´ë¦„
        config: ì‹¤í—˜ ì„¤ì •
        episode_counts: í˜ì´ì¦ˆë³„ ì—í”¼ì†Œë“œ ìˆ˜ (ì„ íƒì‚¬í•­)
        success_counts: í˜ì´ì¦ˆë³„ ì„±ê³µ ìˆ˜ (ì„ íƒì‚¬í•­)
        phase_names: í˜ì´ì¦ˆ ì´ë¦„ë“¤ (ì„ íƒì‚¬í•­)
    """
    os.makedirs(save_dir, exist_ok=True)
    
    # ì„¤ì • ì €ì¥
    if config:
        save_experiment_config(config, save_dir, task_name)
    
    # ê·¸ë˜í”„ë“¤ ì €ì¥
    plot_history(history, os.path.join(save_dir, "training_history.png"), task_name, config)
    plot_episode_returns(episode_returns, os.path.join(save_dir, "episode_returns.png"), task_name, config)
    
    if episode_counts and success_counts:
        plot_phase_success(episode_counts, success_counts, phase_names, 
                          os.path.join(save_dir, "phase_success.png"), task_name, config)
    
    # íˆìŠ¤í† ë¦¬ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œë„ ì €ì¥
    history_path = os.path.join(save_dir, "training_history.json")
    with open(history_path, 'w', encoding='utf-8') as f:
        json.dump(history, f, indent=2, ensure_ascii=False)
    
    # ì—í”¼ì†Œë“œ ë¦¬í„´ ë°ì´í„°ë„ ì €ì¥
    returns_path = os.path.join(save_dir, "episode_returns.json")
    def to_serializable(r):
        if isinstance(r, np.ndarray):
            return r.tolist()
        elif isinstance(r, np.generic):
            return float(r)
        else:
            return r
    returns_data = [to_serializable(r) for r in episode_returns]
    with open(returns_path, 'w', encoding='utf-8') as f:
        json.dump(returns_data, f, indent=2, ensure_ascii=False)
    
    print(f"ëª¨ë“  ê²°ê³¼ê°€ {save_dir} í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ì €ì¥ëœ íŒŒì¼ë“¤:")
    print(f"  - training_history.png")
    print(f"  - episode_returns.png")
    if episode_counts and success_counts:
        print(f"  - phase_success.png")
    print(f"  - training_history.json")
    print(f"  - episode_returns.json")
    if config:
        print(f"  - config_{task_name}_*.json")